# LLM Configuration

Configure AI providers for workflows

---

Configure OpenAI or Anthropic as your LLM provider to enable AI features in workflows.

## Supported Providers

| Provider | Models |
|----------|--------|
| **OpenAI** | GPT-4o, GPT-4, GPT-3.5 Turbo |
| **Anthropic** | Claude 3.5 Sonnet, Claude Opus 4.5 |

## Configure LLM Provider

1. Navigate to **Settings** > **AI Configuration**

2. Select your provider (OpenAI or Anthropic)

3. Enter your API key

4. Click **Test Connection** to verify and fetch available models

5. Save the configuration

After testing the connection, Bifrost fetches and caches the list of available models from your provider.

## Embedding Configuration

For knowledge base / RAG features, configure embeddings:

1. In **Settings** > **AI Configuration**, scroll to **Embeddings**

2. Choose to use the same provider as LLM or configure separately

3. For OpenAI, embeddings use `text-embedding-3-small` (1536 dimensions)

## Usage in Workflows

Once configured, use AI in your workflows:

```python
from bifrost import ai

@workflow
async def summarize_ticket(description: str):
    response = await ai.complete(f"Summarize this ticket: {description}")
    return {"summary": response.content}
```

## Model Overrides

Override the default model per-request:

```python
response = await ai.complete(
    "Complex analysis task",
    model="gpt-4o"  # or "claude-3-5-sonnet-latest"
)
```

## Usage Tracking

Bifrost tracks all AI usage:

- Input/output tokens per call
- Cost calculation based on configured pricing
- Aggregation by workflow, conversation, and organization

View usage reports in **Settings** > **Usage Reports**.

## Pricing Configuration

Configure per-model pricing in **Settings** > **AI Pricing**:

| Field | Description |
|-------|-------------|
| Provider | OpenAI or Anthropic |
| Model | Model display name |
| Input Price | Cost per 1M input tokens |
| Output Price | Cost per 1M output tokens |

If pricing isn't configured for a model, usage is still tracked but costs show as $0.

## Next Steps

- [Using AI in Workflows](/how-to-guides/ai/using-ai-in-workflows) - Completions and streaming
- [Knowledge Bases](/how-to-guides/ai/knowledge-bases) - RAG with vector search